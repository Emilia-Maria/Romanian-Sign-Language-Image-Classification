{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgs2x7Q_nzDn"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKQLwH0onpNE"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.layers import Dense, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras import layers, callbacks, utils, regularizers\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.utils import image_dataset_from_directory\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import os, pathlib, random\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jagHFM2mn3bP"
      },
      "source": [
        "# CONSTANTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "navrz6yln4Vd"
      },
      "outputs": [],
      "source": [
        "DATASET_DIR = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/Ro_Sign_language_Dataset\")\n",
        "MODEL_SAVE_DIR = pathlib.Path(\"/content/drive/MyDrive/Proiect Licenta/Saves/V2\")\n",
        "SAVE_NAME = f'Model full regularized'\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_HEIGHT = 128\n",
        "IMAGE_WIDTH = 128\n",
        "VALIDATION_SPLIT = 0.2\n",
        "EPOCHS = 50\n",
        "UNITS = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGq2fW_Qn7X9"
      },
      "source": [
        "# PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdkZalZTn8jl",
        "outputId": "1b86ebfa-c641-4379-f320-037438c592dc"
      },
      "outputs": [],
      "source": [
        "train_dataset = image_dataset_from_directory(DATASET_DIR / \"train\",\n",
        "                                             image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             label_mode='categorical')\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(DATASET_DIR / \"validation\",\n",
        "                                                  image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  label_mode='categorical',\n",
        "                                                  shuffle=False)\n",
        "\n",
        "test_dataset = image_dataset_from_directory(DATASET_DIR / \"test\",\n",
        "                                            image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            label_mode='categorical',\n",
        "                                            shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZrcXicjn_66"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential([layers.RandomFlip(\"horizontal\"),\n",
        "                                      layers.RandomRotation(0.05),\n",
        "                                      layers.RandomZoom(0.2)])\n",
        "\n",
        "rescale = layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaC6jlrD7M3v"
      },
      "source": [
        "# 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMPnyUdG7WlE"
      },
      "source": [
        "## ARCHITECTURE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt2vLxDQ7WlJ",
        "outputId": "12dc3fe3-b2fb-4ff5-f90e-484910b412d5"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = rescale(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.L2())(x)\n",
        "outputs = layers.Dense(26, activation=\"softmax\")(x)\n",
        "my_model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "my_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qL3drOYN7WlK"
      },
      "outputs": [],
      "source": [
        "my_model.compile(loss=\"categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afdHnsEG7WlK",
        "outputId": "f7ea3929-9c93-473f-f3a1-d075b3901461"
      },
      "outputs": [],
      "source": [
        "callbacks = [keras.callbacks.ModelCheckpoint(filepath = str(MODEL_SAVE_DIR / f'{SAVE_NAME}256.model.keras'),\n",
        "                                             save_best_only=True,\n",
        "                                             monitor=\"val_loss\")]\n",
        "\n",
        "history = my_model.fit(train_dataset,\n",
        "                       epochs=EPOCHS,\n",
        "                       validation_data=validation_dataset,\n",
        "                       callbacks=callbacks)\n",
        "\n",
        "np.save(MODEL_SAVE_DIR / f'{SAVE_NAME}256.history.npy', history.history)\n",
        "my_model.save(MODEL_SAVE_DIR / f'{SAVE_NAME}256.model.tf', save_format='tf')\n",
        "my_model.save(MODEL_SAVE_DIR / f'{SAVE_NAME}256.model.h5', save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "c9DoI3QM7WlK",
        "outputId": "a5bd8304-aabb-4e26-dc3e-73bff28f99a9"
      },
      "outputs": [],
      "source": [
        "history = np.load(MODEL_SAVE_DIR / f'{SAVE_NAME}256.history.npy', allow_pickle=True).item()\n",
        "\n",
        "accuracy = history[\"accuracy\"]\n",
        "val_accuracy = history[\"val_accuracy\"]\n",
        "loss = history[\"loss\"]\n",
        "val_loss = history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfX2ypzV7WlK"
      },
      "source": [
        "## EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-EqgZYa7WlK",
        "outputId": "92fb4c74-18cd-4eff-d2c1-3337064bd531"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(MODEL_SAVE_DIR / f'{SAVE_NAME}256.model.keras')\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX6qiSas7WlK",
        "outputId": "024d4d11-95c1-4bdb-f887-c6a78f86cb2e"
      },
      "outputs": [],
      "source": [
        "class_names = test_dataset.class_names\n",
        "y_pred = np.argmax(test_model.predict(test_dataset), axis=-1)\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "y_true = np.argmax(y_true, axis=-1)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "_I3I2yLh7WlL",
        "outputId": "fef0d13b-0d5a-4365-87da-fa7a95dea33e"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, classes):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "plot_confusion_matrix(y_true, y_pred, classes=class_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjxu6Uq5lNVF"
      },
      "source": [
        "# 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHyvucM3lNVv"
      },
      "source": [
        "## ARCHITECTURE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-G7l0PplNVw",
        "outputId": "80e2c711-9bf9-4c7c-c24b-2f8c573e7dad"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = rescale(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.L2())(x)\n",
        "outputs = layers.Dense(26, activation=\"softmax\")(x)\n",
        "my_model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "my_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy1u8210lNV0"
      },
      "outputs": [],
      "source": [
        "my_model.compile(loss=\"categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaHjkqsClNV0",
        "outputId": "10ee243c-0257-43c6-de8a-2f1b3e85fe15"
      },
      "outputs": [],
      "source": [
        "callbacks = [keras.callbacks.ModelCheckpoint(filepath = str(MODEL_SAVE_DIR / f'{SAVE_NAME}128.model.keras'),\n",
        "                                             save_best_only=True,\n",
        "                                             monitor=\"val_loss\")]\n",
        "\n",
        "history = my_model.fit(train_dataset,\n",
        "                       epochs=EPOCHS,\n",
        "                       validation_data=validation_dataset,\n",
        "                       callbacks=callbacks)\n",
        "\n",
        "np.save(MODEL_SAVE_DIR / f'{SAVE_NAME}128.history.npy', history.history)\n",
        "my_model.save(MODEL_SAVE_DIR / f'{SAVE_NAME}128.model.tf', save_format='tf')\n",
        "my_model.save(MODEL_SAVE_DIR / f'{SAVE_NAME}128.model.h5', save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "Eeuy4aMrlNV1",
        "outputId": "bcf6a015-48de-4798-b652-5bbe4b85fc3c"
      },
      "outputs": [],
      "source": [
        "history = np.load(MODEL_SAVE_DIR / f'{SAVE_NAME}128.history.npy', allow_pickle=True).item()\n",
        "\n",
        "accuracy = history[\"accuracy\"]\n",
        "val_accuracy = history[\"val_accuracy\"]\n",
        "loss = history[\"loss\"]\n",
        "val_loss = history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hENnAxL6lNV5"
      },
      "source": [
        "## EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvcxHNSclNV6",
        "outputId": "24227bf9-654e-4451-ed80-7e6f3f8b85d5"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(MODEL_SAVE_DIR / f'{SAVE_NAME}128.model.keras')\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiJIMctQlNV7",
        "outputId": "77fdf858-331c-46d0-c637-87050f636124"
      },
      "outputs": [],
      "source": [
        "class_names = test_dataset.class_names\n",
        "y_pred = np.argmax(test_model.predict(test_dataset), axis=-1)\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "y_true = np.argmax(y_true, axis=-1)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "UxnC4vpYlNV8",
        "outputId": "f0a7e88b-5eff-424a-f9fc-f5d8fb181d22"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, classes):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "plot_confusion_matrix(y_true, y_pred, classes=class_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UE2arviuDT3"
      },
      "source": [
        "# 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpiSqCDnuDUg"
      },
      "source": [
        "## ARCHITECTURE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8Xhu59_uDUg",
        "outputId": "3b2f888f-b2e4-4b1f-c056-e05d55c3eaae"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = rescale(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.L2())(x)\n",
        "outputs = layers.Dense(26, activation=\"softmax\")(x)\n",
        "my_model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "my_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdAK8QfIuDUi"
      },
      "outputs": [],
      "source": [
        "my_model.compile(loss=\"categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEI9xvHfuDUj",
        "outputId": "339a6312-9950-41cd-f9cf-3ed3b28bdcb0"
      },
      "outputs": [],
      "source": [
        "callbacks = [keras.callbacks.ModelCheckpoint(filepath = str(MODEL_SAVE_DIR / f'{SAVE_NAME}512.model.keras'),\n",
        "                                             save_best_only=True,\n",
        "                                             monitor=\"val_loss\")]\n",
        "\n",
        "history = my_model.fit(train_dataset,\n",
        "                       epochs=EPOCHS,\n",
        "                       validation_data=validation_dataset,\n",
        "                       callbacks=callbacks)\n",
        "\n",
        "np.save(MODEL_SAVE_DIR / f'{SAVE_NAME}512.history.npy', history.history)\n",
        "my_model.save(MODEL_SAVE_DIR / f'{SAVE_NAME}512.model.tf', save_format='tf')\n",
        "my_model.save(MODEL_SAVE_DIR / f'{SAVE_NAME}512.model.h5', save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "RQOLXBVYuDUk",
        "outputId": "20a129a1-5b27-4774-858a-34764663e3d8"
      },
      "outputs": [],
      "source": [
        "history = np.load(MODEL_SAVE_DIR / f'{SAVE_NAME}512.history.npy', allow_pickle=True).item()\n",
        "\n",
        "accuracy = history[\"accuracy\"]\n",
        "val_accuracy = history[\"val_accuracy\"]\n",
        "loss = history[\"loss\"]\n",
        "val_loss = history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlVg2I1PuDUm"
      },
      "source": [
        "## EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbALr3awuDUo",
        "outputId": "cfbb5773-d494-4878-b54c-7344b354d75c"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(MODEL_SAVE_DIR / f'{SAVE_NAME}512.model.keras')\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az4F4hnAuDUp",
        "outputId": "624a7435-4ff7-4699-e5f6-1d691ea24cdc"
      },
      "outputs": [],
      "source": [
        "class_names = test_dataset.class_names\n",
        "y_pred = np.argmax(test_model.predict(test_dataset), axis=-1)\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "y_true = np.argmax(y_true, axis=-1)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "fWOUjhANuDUq",
        "outputId": "aa86a65a-1d41-48e3-c502-f86e057883aa"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, classes):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "plot_confusion_matrix(y_true, y_pred, classes=class_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ttUn_gQz9l6"
      },
      "source": [
        "# 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh2SrOMcz9ma"
      },
      "source": [
        "## ARCHITECTURE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVpPuXZfz9mb",
        "outputId": "0af87216-5bb9-416b-930b-f391a1398dbc"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = rescale(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.L2())(x)\n",
        "outputs = layers.Dense(26, activation=\"softmax\")(x)\n",
        "my_model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "my_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvAkuIMVz9mb"
      },
      "outputs": [],
      "source": [
        "my_model.compile(loss=\"categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KXm-VL-z9mc",
        "outputId": "7fe3c5b7-3ae6-42c3-9548-5b5d977c2823"
      },
      "outputs": [],
      "source": [
        "callbacks = [keras.callbacks.ModelCheckpoint(filepath = str(MODEL_SAVE_DIR / f'{SAVE_NAME}64.model.keras'),\n",
        "                                             save_best_only=True,\n",
        "                                             monitor=\"val_loss\")]\n",
        "\n",
        "history = my_model.fit(train_dataset,\n",
        "                       epochs=EPOCHS,\n",
        "                       validation_data=validation_dataset,\n",
        "                       callbacks=callbacks)\n",
        "\n",
        "np.save(MODEL_SAVE_DIR / f'{SAVE_NAME}64.history.npy', history.history)\n",
        "my_model.save(MODEL_SAVE_DIR / f'{SAVE_NAME}64.model.tf', save_format='tf')\n",
        "my_model.save(MODEL_SAVE_DIR / f'{SAVE_NAME}64.model.h5', save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "8E7035gFz9mc",
        "outputId": "6622a75f-30b4-49ca-8969-53e6bd98c5a4"
      },
      "outputs": [],
      "source": [
        "history = np.load(MODEL_SAVE_DIR / f'{SAVE_NAME}64.history.npy', allow_pickle=True).item()\n",
        "\n",
        "accuracy = history[\"accuracy\"]\n",
        "val_accuracy = history[\"val_accuracy\"]\n",
        "loss = history[\"loss\"]\n",
        "val_loss = history[\"val_loss\"]\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfLNYKE-z9md"
      },
      "source": [
        "## EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2ilQC6ez9md",
        "outputId": "698d7150-3abb-43e8-d7ea-9ec1520e0c04"
      },
      "outputs": [],
      "source": [
        "test_model = keras.models.load_model(MODEL_SAVE_DIR / f'{SAVE_NAME}64.model.keras')\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3owf8IJez9md",
        "outputId": "ca8b5757-b637-4cb7-b9a7-fea4ab51e398"
      },
      "outputs": [],
      "source": [
        "class_names = test_dataset.class_names\n",
        "y_pred = np.argmax(test_model.predict(test_dataset), axis=-1)\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "y_true = np.argmax(y_true, axis=-1)\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "tvvveUADz9me",
        "outputId": "64ec4749-db51-47b7-9b0d-e827f7356041"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, classes):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], 'd'),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "plot_confusion_matrix(y_true, y_pred, classes=class_names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMeReC5kAftm"
      },
      "source": [
        "# VIZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QwbKdcvMAg79",
        "outputId": "9678f52f-1c38-4d73-ec26-8b37489f95ee"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "unit_sizes = [64, 128, 256, 512]\n",
        "\n",
        "histories = {}\n",
        "for units in unit_sizes:\n",
        "    history_path = MODEL_SAVE_DIR / f'{SAVE_NAME}{units}.history.npy'\n",
        "    histories[units] = np.load(history_path, allow_pickle=True).item()\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "for units in unit_sizes:\n",
        "    plt.plot(histories[units]['accuracy'], linestyle='-', label=f'Train Acc {units} units')\n",
        "    plt.plot(histories[units]['val_accuracy'], linestyle='--', label=f'Val Acc {units} units')\n",
        "plt.title('Acuratețe pe antrenare / validare')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "for units in unit_sizes:\n",
        "    plt.plot(histories[units]['loss'], linestyle='-', label=f'Train Loss {units} units')\n",
        "    plt.plot(histories[units]['val_loss'], linestyle='--', label=f'Val Loss {units} units')\n",
        "plt.title('Cost pe antrenare / validare')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "CaC6jlrD7M3v",
        "Bjxu6Uq5lNVF",
        "5UE2arviuDT3",
        "5ttUn_gQz9l6"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
